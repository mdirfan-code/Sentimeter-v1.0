{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreTrained Model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-5h1w6fix\n",
      "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-5h1w6fix\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): transformers==4.22.0.dev0 from git+https://github.com/huggingface/transformers.git in /home/mdirfan-code/.local/lib/python3.8/site-packages\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers==4.22.0.dev0) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (1.21.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.8.1 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: requests in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers==4.22.0.dev0) (20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.22.0.dev0) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (2022.7.25)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (4.64.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.8.1->transformers==4.22.0.dev0) (4.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.22.0.dev0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers==4.22.0.dev0) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from requests->transformers==4.22.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.22.0.dev0) (2019.11.28)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.22.0.dev0-py3-none-any.whl size=4729658 sha256=2a936252ab65f3acca06c1d056fd97a1df5344e19ca0ed4d2bb4ce47f483d459\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-84d33z9q/wheels/05/0a/97/64ae47c27ba95fae2cb5838e7b4b7247a34d4a8ba5f7092de2\n",
      "Successfully built transformers\n"
     ]
    }
   ],
   "source": [
    "# Transformers installation\n",
    "# ! pip install transformers\n",
    "! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdirfan-code/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-08-18 17:41:05.275652: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-18 17:41:05.275798: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "2022-08-18 17:41:13.567812: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-18 17:41:13.567884: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-18 17:41:13.567910: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Mi-Notebook-Ultra): /proc/driver/nvidia/version does not exist\n",
      "2022-08-18 17:41:13.569568: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-18 17:41:13.614132: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BertModel = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:41:29.964929: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "2022-08-18 17:41:30.291858: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "2022-08-18 17:41:30.391500: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "2022-08-18 17:41:47.409080: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "2022-08-18 17:41:48.848505: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "Some layers from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "BertModel = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '2 stars', 'score': 0.36853718757629395}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertModel(\"आगही भूलने देती नहीं हस्ती का मआल\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For every retweet this gets Pedigree will donate one bowl of 1 dog food to dogs in need! tweetforbowls \n"
     ]
    }
   ],
   "source": [
    "import scrapper\n",
    "# data(\"Climate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Switch off the cameras. You are either helping or campaigning. How long did he stay? 1 ',\n",
       " 'jss tem um amigo do eugenio q jura por deus q ele esta abalando fazendo reels falando de politica mana vai dormi ',\n",
       " ' No kizzy.. We fasho got some highlight reels!',\n",
       " ' Reels ah ',\n",
       " ' Hard to compete when we ve got zander on IG reels ',\n",
       " ' ',\n",
       " 'Networks should spend less on 15 second commercials for their TV shows and buy 1 minute slots in less volume and a ',\n",
       " 'Ultimamente me gusta grabar videos cortos para luego hacerlos reels',\n",
       " ' BETULLL! I can relate mba apalagi bikin keinget sama penyebab mba lagi down sekarang. Jadi emang baiknya ',\n",
       " 'Bug n hi bir ey yapm cam sadece bo bo yatarak nstagram reels kayd r cam',\n",
       " ' bora faze uma aposta quem fazer o desenho mais bala ganha quem perder tem que postar aquele reels do ',\n",
       " 'This is how you use the IG algorithm for your benefits Post very 1 or 2 days 2 reels a day without any wate ',\n",
       " 'Reels tbtb naik grgr ucup like 2hari lalu pdhl ga tag skrg direpost admin pestapora keknya lg rajin jam sgni ngerepost2 ',\n",
       " ' Reels and wheels XL',\n",
       " \"Reels for today's match\",\n",
       " 'C mle lem Trib n .Rizespor Bodrumspor ma yk s Rizespor Rize ye ilmavi niCA liseCA atmaca karadeniz ',\n",
       " '02.10.22 Wonho no Instagram Ele postou um reels com o Concept Film 1 WONHO BITTER ',\n",
       " 'ye reels wali ladkiya kaha jati hogi garba khelne',\n",
       " ' The tiktoks the reels the texts in them and anagrams',\n",
       " ' Reels and wheels XL!!!',\n",
       " 'Small bedroom design manikemagehithe shorts smallbedroom bedroomdesign short reels reel WoW ',\n",
       " 'Cute kittens cats love reels filmsteller shorts maroon5 kittens Russian cats love like What Cats Like ',\n",
       " ' BurkinaFaso les conditions amp revendications qui ont amen Damiba au pouvoir sont similaires celles qui am nent ',\n",
       " ' kalau reels IG random kah? padahal udah enak tuh dari kemaren fypnya konseran terus. jadi gak sabar git ',\n",
       " ' THIS IS AN ART ACCOUNT I might make a few reels of sketch gt line arts gt finals for fun later but not ALL THE TIME!!!!!']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = scrapper.data(\"reels\")\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('When the boycott of films continues. BoycottbollywoodForever BoycottBollywood BoycottBrahmastra BoycottPathan ',\n",
       "  [{'label': '1 star', 'score': 0.5537239909172058}]),\n",
       " (' AmirKhan KareenaKapoorKhan ',\n",
       "  [{'label': '3 stars', 'score': 0.24341237545013428}]),\n",
       " ('Celebrating AzaadiKaAmritMahotsav At Tagore Auditorium OsmaniaUniversity Hyderabad Watching ',\n",
       "  [{'label': '5 stars', 'score': 0.5429187417030334}]),\n",
       " ('Celebrating Azadi ka Amrit mohatsav at Osmania University Tagore auditorium. ',\n",
       "  [{'label': '5 stars', 'score': 0.5842553973197937}]),\n",
       " (\" BoycottVikramVedha BoycottLaalSinghChadha They are khan's Turky is anty for India but Amirkhan had din \",\n",
       "  [{'label': '1 star', 'score': 0.6276048421859741}]),\n",
       " (' ! ! AmirKhan boycottLaalSinghChadha ',\n",
       "  [{'label': '1 star', 'score': 0.7432438135147095}]),\n",
       " (' ', [{'label': '4 stars', 'score': 0.2846148908138275}]),\n",
       " (' Bollywood Movies Boycott ArjunKapoor HrithikRoshan AmirKhan Actor Trend ',\n",
       "  [{'label': '1 star', 'score': 0.4731176197528839}]),\n",
       " ('TOP SABSE BADA DISASTER FILMS IN BOLLYWOOD LSC ne Zero ko cross karke no disaster film now.. AmirKhan ',\n",
       "  [{'label': '5 stars', 'score': 0.7166112065315247}]),\n",
       " (' ', [{'label': '4 stars', 'score': 0.2846148908138275}]),\n",
       " (' BoycottLalSinghChaddha BoycottLalSinghChadha AmirKhan ',\n",
       "  [{'label': '1 star', 'score': 0.6391341686248779}]),\n",
       " (' KHUCHH BI ES ', [{'label': '3 stars', 'score': 0.270829439163208}]),\n",
       " (' . KBC ', [{'label': '3 stars', 'score': 0.24738597869873047}]),\n",
       " ('Shame on u khawaja ventilater ',\n",
       "  [{'label': '1 star', 'score': 0.579378068447113}]),\n",
       " (' BoycottDobaara boycoottlalsinghcadda AmirKhan KareenaKapoor TapsiPannu ArjunKapoor ',\n",
       "  [{'label': '1 star', 'score': 0.6965025067329407}])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = []\n",
    "c = {\"5 stars\":0,\"4 stars\":0,\"3 stars\":0,\"2 stars\":0,\"1 star\":0}\n",
    "for i in ll:\n",
    "    r = BertModel(i)\n",
    "    ans.append((i,r))\n",
    "    c[r[0]['label']] +=1\n",
    "pos = c[\"5 stars\"]+c[\"4 stars\"]\n",
    "nut = c[\"3 stars\"]\n",
    "neg = c[\"1 star\"]+c[\"2 stars\"]\n",
    "\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 7 3\n"
     ]
    }
   ],
   "source": [
    "print(pos,neg,nut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 22:04:44.203469: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-02 22:04:44.203684: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-02 22:04:49.652953: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-02 22:04:49.653004: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-02 22:04:49.653019: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Mi-Notebook-Ultra): /proc/driver/nvidia/version does not exist\n",
      "2022-10-02 22:04:49.653287: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "import sentimeterModel as sm \n",
    "\n",
    "model1 = sm.SentimeterModel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "copy() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2859/968506474.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/Sentimeter-v1.0/BERT_Model/sentimeterModel.py\u001b[0m in \u001b[0;36mfeedData\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeedData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecentData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: copy() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "model1.feedData(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 22.727272727272727,\n",
       " 'Negative': 63.63636363636363,\n",
       " 'Nuteral': 13.636363636363637}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.analyzeResult(\"dkkdkk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "res[\"tt\"] = []\n",
    "res[\"tt\"].append({\"p\":8,\"n\":9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['I can t believe people are still living like this as though it s possible to avoid a virus forever. ',\n",
       "   ' Trump started from 0 ',\n",
       "   ' Ele criou o virus? quem apoia um ladr o mau carater e mais desonesto do que ele inclusive PCC e co ',\n",
       "   'T certo ela pode pegar o v rus da burrice! ',\n",
       "   \" Jamais je ne dirais qu'on peut radiquer un virus. Un virus est une machine biologiquement f \",\n",
       "   ' MuchoGustoMega ChaoMascarilla es un logro de todas las pers ',\n",
       "   \" What is it's ? I agree that we should first focus on the virus. However i can't stop thinking ab \",\n",
       "   ' ',\n",
       "   ' Hoe deed je dat al die jaren voor 2020 toen mensen strontziek waren door influenza of ieder ander vi ',\n",
       "   '6 8 ... wie dreist wir verarscht wurden. Daher ein kleiner R ckblick auf die offizielle Version gt Hier gibt es ei ',\n",
       "   ' Ich h re mir gerne dumme Menschen an ',\n",
       "   'missing nomin rn but cocoa and cororong virus wahaha ',\n",
       "   ' Spike protein vax or virus damages cells throughout your body your b ',\n",
       "   ' Potenziell t dlich in meiner Altersgruppe keine 0.2 insofern man sich erst infiziert was ich bis ',\n",
       "   'Here we go again CovidScared The main Covid symptoms as immune evasive strains kickstart new virus wave in U ',\n",
       "   ' It s so sad that our officials lied for the past two years saying masks and social distancing would prevent ',\n",
       "   ' Logo mais voc PETISTA DE MERDA vai dizer que Bolsonaro inventou o v rus. s ',\n",
       "   ' it would be the ultimate self own if we as a species die off because someone kept some sort of release th ',\n",
       "   ' No lo he abierto por si tiene un virus o algo',\n",
       "   \" You're more likely to have the heart issues from the sars cov 2 virus than the vaccine\",\n",
       "   ' ',\n",
       "   'Sok then this is not financial advice nor any type of recommendation this is educational perhaps I discuss educa '],\n",
       "  [{'Positive': 22.727272727272727,\n",
       "    'Negative': 63.63636363636363,\n",
       "    'Nuteral': 13.636363636363637}])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fetchHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
