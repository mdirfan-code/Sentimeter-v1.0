{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreTrained Model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-5h1w6fix\n",
      "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-5h1w6fix\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): transformers==4.22.0.dev0 from git+https://github.com/huggingface/transformers.git in /home/mdirfan-code/.local/lib/python3.8/site-packages\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers==4.22.0.dev0) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (1.21.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.8.1 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (0.8.1)\n",
      "Requirement already satisfied: requests in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers==4.22.0.dev0) (20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers==4.22.0.dev0) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (2022.7.25)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (4.64.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from transformers==4.22.0.dev0) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.8.1->transformers==4.22.0.dev0) (4.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers==4.22.0.dev0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers==4.22.0.dev0) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mdirfan-code/.local/lib/python3.8/site-packages (from requests->transformers==4.22.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers==4.22.0.dev0) (2019.11.28)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.22.0.dev0-py3-none-any.whl size=4729658 sha256=2a936252ab65f3acca06c1d056fd97a1df5344e19ca0ed4d2bb4ce47f483d459\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-84d33z9q/wheels/05/0a/97/64ae47c27ba95fae2cb5838e7b4b7247a34d4a8ba5f7092de2\n",
      "Successfully built transformers\n"
     ]
    }
   ],
   "source": [
    "# Transformers installation\n",
    "# ! pip install transformers\n",
    "! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdirfan-code/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-08-18 17:41:05.275652: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-18 17:41:05.275798: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "2022-08-18 17:41:13.567812: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-18 17:41:13.567884: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-18 17:41:13.567910: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Mi-Notebook-Ultra): /proc/driver/nvidia/version does not exist\n",
      "2022-08-18 17:41:13.569568: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-18 17:41:13.614132: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BertModel = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 17:41:29.964929: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "2022-08-18 17:41:30.291858: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "2022-08-18 17:41:30.391500: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "2022-08-18 17:41:47.409080: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "2022-08-18 17:41:48.848505: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 325260288 exceeds 10% of free system memory.\n",
      "Some layers from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_file vocab.txt\n",
      "tokenizer_file tokenizer.json\n",
      "added_tokens_file added_tokens.json\n",
      "special_tokens_map_file special_tokens_map.json\n",
      "tokenizer_config_file tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "BertModel = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '2 stars', 'score': 0.36853718757629395}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertModel(\"आगही भूलने देती नहीं हस्ती का मआल\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapper\n",
    "# data(\"Climate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When the boycott of films continues. BoycottbollywoodForever BoycottBollywood BoycottBrahmastra BoycottPathan ',\n",
       " ' AmirKhan KareenaKapoorKhan ',\n",
       " 'Celebrating AzaadiKaAmritMahotsav At Tagore Auditorium OsmaniaUniversity Hyderabad Watching ',\n",
       " 'Celebrating Azadi ka Amrit mohatsav at Osmania University Tagore auditorium. ',\n",
       " \" BoycottVikramVedha BoycottLaalSinghChadha They are khan's Turky is anty for India but Amirkhan had din \",\n",
       " ' ! ! AmirKhan boycottLaalSinghChadha ',\n",
       " ' ',\n",
       " ' Bollywood Movies Boycott ArjunKapoor HrithikRoshan AmirKhan Actor Trend ',\n",
       " 'TOP SABSE BADA DISASTER FILMS IN BOLLYWOOD LSC ne Zero ko cross karke no disaster film now.. AmirKhan ',\n",
       " ' ',\n",
       " ' BoycottLalSinghChaddha BoycottLalSinghChadha AmirKhan ',\n",
       " ' KHUCHH BI ES ',\n",
       " ' . KBC ',\n",
       " 'Shame on u khawaja ventilater ',\n",
       " ' BoycottDobaara boycoottlalsinghcadda AmirKhan KareenaKapoor TapsiPannu ArjunKapoor ']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = scrapper.data(\"amirkhan\")\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('When the boycott of films continues. BoycottbollywoodForever BoycottBollywood BoycottBrahmastra BoycottPathan ',\n",
       "  [{'label': '1 star', 'score': 0.5537239909172058}]),\n",
       " (' AmirKhan KareenaKapoorKhan ',\n",
       "  [{'label': '3 stars', 'score': 0.24341237545013428}]),\n",
       " ('Celebrating AzaadiKaAmritMahotsav At Tagore Auditorium OsmaniaUniversity Hyderabad Watching ',\n",
       "  [{'label': '5 stars', 'score': 0.5429187417030334}]),\n",
       " ('Celebrating Azadi ka Amrit mohatsav at Osmania University Tagore auditorium. ',\n",
       "  [{'label': '5 stars', 'score': 0.5842553973197937}]),\n",
       " (\" BoycottVikramVedha BoycottLaalSinghChadha They are khan's Turky is anty for India but Amirkhan had din \",\n",
       "  [{'label': '1 star', 'score': 0.6276048421859741}]),\n",
       " (' ! ! AmirKhan boycottLaalSinghChadha ',\n",
       "  [{'label': '1 star', 'score': 0.7432438135147095}]),\n",
       " (' ', [{'label': '4 stars', 'score': 0.2846148908138275}]),\n",
       " (' Bollywood Movies Boycott ArjunKapoor HrithikRoshan AmirKhan Actor Trend ',\n",
       "  [{'label': '1 star', 'score': 0.4731176197528839}]),\n",
       " ('TOP SABSE BADA DISASTER FILMS IN BOLLYWOOD LSC ne Zero ko cross karke no disaster film now.. AmirKhan ',\n",
       "  [{'label': '5 stars', 'score': 0.7166112065315247}]),\n",
       " (' ', [{'label': '4 stars', 'score': 0.2846148908138275}]),\n",
       " (' BoycottLalSinghChaddha BoycottLalSinghChadha AmirKhan ',\n",
       "  [{'label': '1 star', 'score': 0.6391341686248779}]),\n",
       " (' KHUCHH BI ES ', [{'label': '3 stars', 'score': 0.270829439163208}]),\n",
       " (' . KBC ', [{'label': '3 stars', 'score': 0.24738597869873047}]),\n",
       " ('Shame on u khawaja ventilater ',\n",
       "  [{'label': '1 star', 'score': 0.579378068447113}]),\n",
       " (' BoycottDobaara boycoottlalsinghcadda AmirKhan KareenaKapoor TapsiPannu ArjunKapoor ',\n",
       "  [{'label': '1 star', 'score': 0.6965025067329407}])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = []\n",
    "c = {\"5 stars\":0,\"4 stars\":0,\"3 stars\":0,\"2 stars\":0,\"1 star\":0}\n",
    "for i in ll:\n",
    "    r = BertModel(i)\n",
    "    ans.append((i,r))\n",
    "    c[r[0]['label']] +=1\n",
    "pos = c[\"5 stars\"]+c[\"4 stars\"]\n",
    "nut = c[\"3 stars\"]\n",
    "neg = c[\"1 star\"]+c[\"2 stars\"]\n",
    "\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 7 3\n"
     ]
    }
   ],
   "source": [
    "print(pos,neg,nut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
